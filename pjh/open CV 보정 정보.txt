
cv2.TERM_CRITERIA_EPS = 종료 조건의 타입으로 주어진 정확도(epsilon 인자)에 도달하면 반복을 중단
cv2.TERM_CRITERIA_MAX_ITER = max_iter 인자에 지정된 횟수만큼 반복하고 중단
cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER를 조합해 사용하면 두가지 조건 중 하나가 만족되면 반복이 중단

Calibration Flag 조합
cv2.fisheye.CALIB_RECOMPUTE_EXTRINSIC = 외부는 내부 최적화를 반복할 때마다 다시 계산
cv2.fisheye.CALIB_CHECK_COND = 함수는 조건 번호의 유효성을 확인
cv2.fisheye.CALIB_FIX_SKEW = 스큐 계수(알파)는 0으로 설정되고 0을 유지

numpy.zeros(shape, dtype=float, order='C', *, like=None) = 0으로 채워진 주어진 모양과 유형의 새 배열을 반환
shape = int or int 튜플 e.g., (2, 3) or 2. -> (2, 3) = arr[2][3], (2, 3, 5) = arr[2][3][5]

In [11]: np.mgrid[0:2,0:3]
Out[11]:
array([[[0, 0, 0],
        [1, 1, 1]],

       [[0, 1, 2],
        [0, 1, 2]]])

In [12]: np.mgrid[0:2,0:3].T  # (matrix) transpose 전치행렬
Out[12]:
array([[[0, 0],
        [1, 0]],

       [[0, 1],
        [1, 1]],

       [[0, 2],
        [1, 2]]])

In [13]: np.mgrid[0:2,0:3].T.reshape(-1, 2)  # reshape to an Nx2 matrix
Out[13]:
array([[0, 0],
       [1, 0],
       [0, 1],
       [1, 1],
       [0, 2],
       [1, 2]])
이 때, reshape(-1, 2) -> -1: 자릿수에 따라 알잘딱 개념(2차원 배열 위치), 2(1차원 배열의 개수) = arr[n][2]

glob.glob() : 디렉토리 내 파일, 폴더 정보 리스트로 반환

image.shape(height, width , channel) = shape 함수를 통해 height, width, channels를 얻을 수 있습니다.
ex)image.shape(:2) => img.shape(height, width)

cv2.findChessboardCorners(image, patternSize[, corners[, flags]]) → retval, corners

image - 8비트 grayscale이거나 color image
patternSize - 체스보드 row, column
corners - 코너를 찾으면 array로 return
만약 ret값이 False라면, 체스 보드 이미지의 패턴 개수를 맞게 했는지 확인하거나 (wc, hc) 체스 보드가 깔끔하게 나온 이미지를 가져와야 한다.

cv2.cornerSubPix(image, corners, winSize, zeroZone, criteria): 입력 영상 image에서 검출된 코너점 corners를 입력하여 코너점의 위치를 부화소 수준으로 다시 계산하여 반환한다.

Parameters
image: input
corners: 코너점
iwnSize: Search Window의 절반 사이즈
zeroZone: Half of the size of the dead region in the middle of the search zone over which the summation in the formula below is not done.
criteria: 종료 시점


cv.fisheye.initUndistortRectifyMap(	K, D, R, P, size, m1type[, map1[, map2]]	) ->	map1, map2
Parameters
K	카메라 고유 매트릭스 cameramatrixK.
D	왜곡 계수의 입력 벡터 (k1,k2,k3,k4).
R	Rectification transformation in the object space: 3x3 1-channel, or vector: 3x1/1x3 1-channel or 1x1 3-channel
	(오브젝트 공간의 정류 변환)
P	새로운 카메라 고유 매트릭스(3x3) 또는 새로운 프로젝션 매트릭스(3x4)
size	왜곡되지 않은 이미지 크기.
m1type	CV_32FC1 또는 CV_16SC2 일 수 있는 첫 번째 출력 맵의 유형입니다
map1	The first output map.
map2	The second output map.

np.eye(n, k=m, dtype=int) = 괄호의 첫 부분은 nxn행렬을 나타내고 k는 정방단위행렬을 기준으로	
어느 부분에 대각행렬을 나타낼껀지 결정하는 부분이다.

cv2.remap(src, map1, map2, interpolation, dst=None, borderMode=None, borderValue=None) -> dst

• src: 입력 영상
• map1: 결과 영상의 (x, y) 좌표가 참조할 입력 영상의 x좌표. 입력 영상과 크기는 같고, 타입은 np.float32인 numpy.ndarray.
• map2: 결과 영상의 (x, y) 좌표가 참조할 입력 영상의 y좌표.
• interpolation: 보간법
• dst: 출력 영상
• borderValue: cv2.BORDER_CONSTANT일 때 사용할 상수 값. 기본값은 0.
• borderMode: 가장자리 픽셀 확장 방식. 기본값은 cv2.BORDER_CONSTANT.

 map1은 x좌표, map2는 y좌표를 의미합니다.


 interpolation 인자를 잘 주는 것이 중요합니다.

1. cv2.INTER_NEAREST - 최근방 이웃 보간법

 가장 빠르지만 퀄리티가 많이 떨어집니다. 따라서 잘 쓰이지 않습니다.

 

2. cv2.INTER_LINEAR - 양선형 보간법(2x2 이웃 픽셀 참조)

 4개의 픽셀을 이용합니다.

 효율성이 가장 좋습니다. 속도도 빠르고 퀄리티도 적당합니다.

 

3. cv2.INTER_CUBIC - 3차회선 보간법(4x4 이웃 픽셀 참조)

 16개의 픽셀을 이용합니다.

 cv2.INTER_LINEAR 보다 느리지만 퀄리티는 더 좋습니다.

 

4. cv2.INTER_LANCZOS4 - Lanczos 보간법 (8x8 이웃 픽셀 참조)

 64개의 픽셀을 이용합니다.

 좀더 복잡해서 오래 걸리지만 퀄리티는 좋습니다.

 

5. cv2.INTER_AREA - 영상 축소시 효과적

 영역적인 정보를 추출해서 결과 영상을 셋팅합니다.

 영상을 축소할 때 이용합니다.


 borderType ; 추가하는 경계의 종류를 지정하기 위한 플래그, 아래와 같은 타입이 존재

1) cv2.BORDER_CONSTANT ; 단색의 경계를 추가하는 것, value에서 색의 지정을 한다.

2) cv2.BORDER_REFLECT ; 거울에 비춘 것 처럼 경계를 지정한다. 예를 들면, 아래와 같은 경계를 만들 수 있다.

; fedcba|abcdefgh|hgfedcb

3) cv2.BORDER_REFLECT_101 / cv2.BORDER_DEFAULT ; cv2.BORDER_REFLECT와 같지만 미세한 차이가 있다

; gfedcb|abcdefgh|gfedcba

4) cv2.BORDER_REPLICATE ; 마지막 요소를 반복해서 표시한다.

; aaaaaa|abcdefgh|hhhhhhh

5) cv2.BORDER_WRAP ; 잘 설명할 수 없지만, 아래와 같이 표시된다.

; cdefgh|abcdefgh|abcdefg

- value ; 플래그가 cv2.BORDER_CONSTANT일 경우 경계 색을 지정할 때 사용한다.























